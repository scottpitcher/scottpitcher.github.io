<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Scott Pitcher's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="icon" type="image/x-icon" href="favicon.jpg">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		
		<!-- Prism.js CSS for syntax highlighting -->
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">

		<!-- Prism.js library -->
		<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>

		<!-- Include the language you need, e.g., Python -->
		<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-laptop-code"></span>
						</div>
						<div class="content">
							<div class="inner">
								<h1>SCOTT PITCHER</h1>
								<p>Data Science • Machine Learning</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#about">About</a></li>
								<li><a href="#projects">Projects</a></li>
								<li><a href="#contact">Contact</a></li>
								<li><a href="resume.pdf">Resume</a></li>
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">
             			 		<!-- About -->
							<article id="about">
								<h2 class="major">About Me!</h2>
								<span class="image main"><img src="images/headshot.jpeg" alt="" /></span>
								<p>Thank you for taking the time to visit my website portfolio! Here I've laid out some of my favourite past projects, and what I'm currently working on/discovering!</p>
								<br>	
								<p>I'm a Data Scientist with 3+ years of experience, specializing in statistical analysis and model development!
								I graduated with a B.S. in Mathematics with a focus in both Data Analysis and Business Intelligence from the University of South Florida. 
								Within Data Science, I've found myself most interested in the applications of neurosymbolic AI and the development of language models.
								Outside of my professional background, I love cooking, taking a walk with music, and constantly challenging myself in the gym; I am currently located in New York City.</p>
								<p>Feel free to check out my GitHub <a href = "https://www.github.com/scottpitcher"> here!</a> or connect with me on <a href = "https://www.linkedin.com/in/scottpitcher1"> LinkedIn</a></p>
							</article>

							<!-- Projects -->
								<article id="projects">
								<h1>Table and Summaries of Projects</h1>
								<p>Below you can find some of my personal projects that I've completed off the clock; while each project is unique in tools and skills, my goal is always the same: challenge myself!</p>
								<p>Each project has report with results and figures, linked in both the table and the summary header! </p>
								<p>Check out my <a href="https://www.github.com/scottpitcher" target="_blank">GitHub!</a></p>
																
								<!--Table of Projects-->
								<div class="table-wrapper">
									<table class="alt">
										<thead>
											<tr>
												<th>Project</th>
												<th>Project Tags</th>
												<th>Description</th>
											</tr>
										</thead>
										<tbody>
											<tr>
											    <td><a href="#pokemonaipage" class="tooltip">Pokémon Platinum AI
											        <span class="tooltiptext"> Click here for project results!</span>
											    </a></td>
											    <td>Computer Vision, PyTorch, Reinforcement Learning, Neural Networks</td>
											    <td>Developed a Deep-Q-Network from scratch to play Pokémon Platinum, trained with Reinforcement Learning (RLHF)</td>
											</tr>
											<tr>
											    <td><a href="#siamesenetworkpage" class="tooltip">Siamese Facial Recognition Network
											        <span class="tooltiptext"> Click here for project results!</span>
											    </a></td>
											    <td>Computer Vision, TensorFlow Keras, Siamese Neural Networks, </td>
											    <td>Built a Siamese-CNN in TensorFlow for facial recognition, trained with custom L1-distance layer</td>
											</tr>
											<tr>
											    <td><a href="#newsretrievalpage" class="tooltip">Personalized Daily News Summarizer
											        <span class="tooltiptext"> Click here for project results!</span>
											    </a></td>
											    <td> Retrieval Augmented Generation (RAG), LLMs, OpenAI API </td>
											    <td>Personalized news summarization app that uses RAG to fetch, filter, and summarize daily news articles according to a user's interests and preferred summary style.</td>
											</tr>
<!-- 											<tr> 
												<td><a href="#knowledgemoviepage"class="tooltip">Knowledge Graph Movie Recommender GNN
													<span class="tooltiptext"> Click here for project results!</span>
												</a></td>
												<td>Knowledge graphs, TensorFlow, Product Analysis</td>
												<td>Recommender trained on two data inputs, utilisng Neo4j knowledge graphs, to recommend a product based on 3 chosen by user.</td>
 											</tr>
 -->
											<tr>
												<td><a href="#ecommercepage"class="tooltip">E-commerce Marketing Analytics and Optimization
													<span class="tooltiptext"> Click here for project results!</span>
												</a></td>
												<td>Predictive Analysis, Scikit-learn, Marketing Analytics</td>
												<td>Oprimised ROI and maximised CLV through the development of machine learning models and statistical analysis</td>
											</tr>
<!-- 											<tr>
												<td><a href="#spotifypage"class="tooltip">Spotify Playlist Recommender/Customer Churn Model
													<span class="tooltiptext"> Click here for project results!</span>
												</a></td>
												<td> Neural Networks, Customer Recommenders, Marketing Analytics, Predictive Analysis</td>
												<td> Utilisng PyTorch to develop a playlist recommender using user data from Spotify API, aimed at decreasing overall churn.</td>
											</tr> -->
										</tbody>
									</table>
								</div>	
								<br>
								<!--Description of Projects-->
									<!-- Pokémon Platinum AI -->
									<h3><a id="pokemon" href = #pokemonaipage>Pokémon Platinum AI</a></h3>
									<span class="image main"><img class="project-image" src="images/pokemon-platinumai-image.png" alt="" /></span>
									<p>Training AI to carry out certain tasks in Pokémon Platinum, utilising computer vision and reinforcement learning (RLHF)!</p>
									<p><a href = #pokemonaipage >(Results/Report)</a> <a href = "https://www.github.com/scottpitcher/PokemonPlatinum.AI">       (GitHub Repo)</a></p>

									<!-- Siamese Facial Recognition Network -->
									<h3><a id="siamese" href = #siamesenetworkpage>Siamese Facial Recognition Network</a></h3>
									<span class="image main"><img class="project-image" src="images/siamese_network_image.png" alt="" /></span>
									<p><a href = #newsretrievalpage >(Results/Report)</a> <a href = "https://github.com/scottpitcher/personalised_news_summariser_rag_llm">       (GitHub Repo)</a></p>

									<!-- Personalized Daily News Summarizer -->
									<h3><a id="news" href = #newsretrievalpage>Personalized Daily News Summarizer</a></h3>
									<span class="image main"><img class="project-image" src="images/news_summarizer_image.png" alt="" /></span>
									<p></p>
									<p>Personalized news summarization app that uses RAG to fetch, filter, and summarize daily news articles according to a user's interests and preferred summary style.<a href = #newsretrievalpage >(Results/Report)</a> <a href = "https://github.com/scottpitcher/personalised_news_summariser_rag_llm">       (GitHub Repo)</a></p>

									<!-- Knowledge Graph Movie Recommender -->
<!-- 									<h3><a id="knowledge" href = #knowledgemoviepage>Knowledge Graph Product Recommender GNN</a></h3>
									<span class="image main"><img class="project-image" src="images/projects/knowldgegraphmovierec/graph.png" alt="" /></span>
									<p>Description pending...</p>
									<p><a href = #knowledgemoviepage >(Results/Report)</a> <a href = "https://github.com/scottpitcher/movie-recommendation-network">       (GitHub Repo)</a></p>
 -->
									<!-- E-Commerce Marketing Analytics and Optimization -->
									<h3><a id="ecommerce" href = #ecommercepage>E-Commerce Marketing Analytics and Optimization</a></h3>
									<span class="image main"><img class="project-image" src="images/ecommerce-image.jpeg" alt="" /></span>
									<p>Deep-diving into consumer data to make data-driven marketing decisions to maximise Customer Life Value (CLV) and optimise discount ROI.</p>
									<p><a href = #ecommercepage >(Results/Report)</a> <a href = "https://github.com/scottpitcher/ecommerce-marketing-analytics-optimization">       (GitHub Repo)</a></p>
								
									
<!-- 									<!-- Spotify Playlist Recommender/Customer Churn Model -->
									<h3><a id="spotify" href = #spotifypage>Spotify Playlist Recommender/Customer Churn Model</a></h3>
									<span class="image main"><img class="project-image" src="images/spotify-logo.jpg" alt="" /></span>
									<p>Utilising the Spotify API to user real-life user data to develop a playlist recommender model aimed at increasing user engagement (i.e. decrease customer churn).</p>
									<p><a href = #spotifypage >(Results/Report)</a> <a href = "https://github.com/scottpitcher/spotify-user-engagement">       (GitHub Repo)</a></p>
 -->
							</article>
						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact</h2>
								<form action="https://formspree.io/f/xyzgaqbn" method="POST">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="4"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Reset" /></li>
									</ul>
								</form>
								<ul class="icons">
										<li><a href="https://www.linkedin.com/in/scottpitcher1" class="icon brands fa-linkedin" target="_blank"><span class="label">Instagram</span></a></li>
										<li><a href="https://www.github.com/scottpitcher" class="icon brands fa-github" target="_blank"><span class="label">Github</span></a></li>
								</ul>
							</article>
						
						<!--Pokemon Project -->
							<article id="pokemonaipage">
								<h1 class="major">Pokémon Platinum AI Project</h1>
								<div style="text-align: center;">
 								 <video controls style="width: 100%; max-width: 500px; height: 420px; object-fit: contain;">
								    <source src="images/projects/pokemonplatinumai/gameplay_short.mov" type="video/mp4">
								    Your browser does not support the video tag.
								  </video>
								</div>

								<div style="text-align: center;"><p>Actual model gameplay!</p></div>
								<h2>Project Summary</h2>
								<p>PyTorch based reinforcement learning model aimed at learning to play specified actions in an open-world video-game (Pokémon Platinum) with the assistance of a computer vision model.<p>
								<p>Check out the GitHub repository <a href="https://github.com/scottpitcher/PokemonPlatinum.AI">here!</a></p>
								<h2>Project Overview</h2>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_1"> 1. Introduction & Technical Stack</a></p>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_2"> 2. Dataset and Preprocessing </a></p>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_3"> 3. Project Structure </a></p> <details><summary style="font-size: 0.9em;"><p style="margin-bottom : 0px;">Subsections</p></summary>
								    <p style="margin-left: 20px; font-size: 0.9em; margin-bottom: 3px;"><a href="#pokemonaipage_3_1">3.1 Computer Vision Model</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#pokemonaipage_3_2">3.2 Model Building and Hyperparameter Tuning</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#pokemonaipage_3_3">3.3 Model Pretraining and Reinforcement Learning Training</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#pokemonaipage_3_4">3.4 Evaluation</a></p>
								</details>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_4"> 4. Challenges and Solutions </a></p>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_5"> 5. Results </a></p>
								<p style="margin-bottom: 5px;"><a href="#pokemonaipage_6"> 6. Conclusion & Future Improvements </a></p>
								<hr width="100%" size="2">
								
								<details>
								  <summary>
								    <h2 id="pokemonaipage_1">1. Introduction & Technical Stack</h2>
								  </summary>
								  <p style="margin-bottom: 15px;">
								    In this project, I set out to build an AI system capable of playing Pokémon Platinum, an open-world, story-driven video game, using computer vision and reinforcement learning with human feedback (RLHF)!
								  </p>
								  <p>
								    The project consists of two main models: an annotation model fine-tuned from YOLOv9s for object detection, and a gameplay model built and trained from scratch with RLHF to make strategic decisions within the game environment.
								  </p>
								  <h3>Technical Stack</h3>
								  <span class="image main">
								    <img class="project-image" src="images/projects/pokemonplatinumai/TechnicalStack.jpeg" alt="" style="display: block; margin: auto; width: 70%; max-width: 800px;" />
								  </span>
								</details>



								<details>
								  <summary>
								    <h2 id="pokemonaipage_2">2. Dataset and Preprocessing</h2>
								  </summary>
								<span class="image main">
								    <img class="project-image" src="images/projects/pokemonplatinumai/datasetpreprocessing.jpeg" alt="" style="display: block; margin: auto; width: 80%; max-width: 800px;" />
								</span>
								<div style="text-align: center; margin-top: -10px;"><p>Dataset preprocessing workflow</p></div>
								<p style="margin-bottom: 15px;">To develop the computer vision annotation model, I manually annotated over 150 gameplay images, labeling key objects such as Pokémon, items, NPCs, and locations. Data augmentations, including random rotation, color jittering, and contrast adjustments, along with resizing transformations, were applied to enhance the model's robustness and generalization.</p>
								<p style="margin-bottom: 15px;">Once the annotation model was trained, it was used to automatically annotate an additional 450 gameplay states. Each state was paired with a set of possible actions (in JSON format)[automated in action_prep.py script] based on nine potential options: A, B, X, Y, Up, Down, Left, Right, and None.</p>
								<p style="margin-bottom: 15px;">These annotated state-action pairs were then used to pretrain the gameplay model, preparing it for the main reinforcement learning phase.</p>
								</details>

								<details>
								  <summary>
									<h2 id="pokemonaipage_3">3. Project Structure</h2>
								  </summary>
								<p style="margin-bottom: 12px;">
								    This project was divided into several key components to develop a robust AI model capable of navigating and interacting within the game environment. Each component played a critical role in building an effective and adaptive gameplay agent:
								</p>
								<p style="margin-left: 20px; margin-bottom: 5px;">1. Development and training of a computer vision annotation model to identify key game elements.</p>
								<p style="margin-left: 20px; margin-bottom: 5px;">2. Construction of a PyTorch-based gameplay model with hyperparameter tuning for optimal performance.</p>
								<p style="margin-left: 20px; margin-bottom: 5px;">3. Pretraining of the gameplay model on annotated data, followed by reinforcement learning with human feedback to refine its interactions.</p>
								<p style="margin-left: 20px; margin-bottom: 5px;">4. Evaluation of the model's performance in achieving in-game objectives.</p>

								<h3 id="pokemonaipage_3_1">3.1 COMPUTER VISION MODEL</h3>
								<p>The computer vision model, based on YOLOv9, detects key objects like Pokémon, items, and NPCs to enable situational awareness for the gameplay model.</p>
								<ul style="margin-left: 20px;">
								    <li><strong>Architecture</strong>: YOLOv9, fine-tuned on a custom dataset of 150 annotated gameplay images.</li>
								    <li><strong>Dataset & Augmentation</strong>: Key objects manually labeled, with data augmentation (rotation, color jitter) applied to improve robustness.</li>
								    <li><strong>Training</strong>: Optimized hyperparameters for high detection accuracy. After training, the model auto-annotated 450 additional images.</li>
								    <li><strong>Outcome</strong>: Achieved high accuracy, providing reliable annotations for the gameplay model's pretraining phase.</li>
								</ul>
								<h4>Sample Annotation</h4>
								<span class="image main">
								    <img class="project-image" src="images/projects/pokemonplatinumai/sample_annotation0.jpeg" alt="" style="display: block; margin: auto; width: 50%; max-width: 800px;" />
								</span>

								<p>Computer vision model building script <a href="https://github.com/scottpitcher/PokemonPlatinum.AI/blob/main/annotation_model.ipynb">here!</a></p>
								<h3 id="pokemonaipage_3_2">3.2 Model Building and Hyperparameter Tuning</h3>
								<p></p>
								<h5> Gameplay Model Architecture</h5>
								<pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python">class PokemonModelLSTM(nn.Module):
    def __init__(self, input_size, conv1_dim, conv2_dim, hidden_size, num_layers, num_actions, use_annotations=False):
        super(PokemonModelLSTM, self).__init__()

        # Store hyperparameters as attributes for easy access
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.num_actions = num_actions
        self.use_annotations = use_annotations
        
        # Convolutional layers to extract features from the game state
        self.conv1 = nn.Conv2d(3, conv1_dim, kernel_size=3, stride=2, padding=1)
        self.conv2 = nn.Conv2d(conv1_dim, conv2_dim, kernel_size=3, stride=2, padding=1)
        
        # LSTM to capture temporal dependencies; input_size will be adjusted dynamically in forward pass
        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)
        
        # Fully connected layer to map the LSTM output to the number of actions
        self.fc = nn.Linear(hidden_size, num_actions)
    
    def forward(self, x, annotations=None):
        # Input x is expected to be of shape (batch_size, seq_len, C, H, W)
        batch_size, seq_len, C, H, W = x.size()
        
        # Reshape input for convolutional layers
        x = x.view(batch_size * seq_len, C, H, W)
        
        # Apply convolutional layers with ReLU activations
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        
        # Flatten the output for the LSTM layer
        x = x.view(batch_size, seq_len, -1)  # Shape: (batch_size, seq_len, conv2_dim * H' * W')
        
        # Dynamically adjust LSTM input size if using annotations
        if self.use_annotations and annotations is not None:
            annotations = annotations.view(batch_size, seq_len, -1)  # Reshape annotations to (batch_size, seq_len, annotation_features)
            x = torch.cat((x, annotations), dim=-1)  # Concatenate along the feature dimension
            lstm_input_size = x.size(-1)  # Set the LSTM input size based on the concatenated features
            
            # Reinitialize LSTM if needed to match new input size
            if lstm_input_size != self.lstm.input_size:
                self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)

        # Apply LSTM
        x, _ = self.lstm(x)                  # x: (batch_size, seq_len, hidden_size)
        
        # Fully connected layer: map the LSTM output to the action space
        x = self.fc(x[:, -1, :])             # Use the last time step's output
        
        return x
</code></pre>

								<!-- <h5>Chosen Model Hyperparameters</h5>
									<p style="margin-bottom: 5px;">num_layers = </p>
									<p style="margin-bottom: 5px;">hidden_size = </p>
									<p style="margin-bottom: 5px;">learning_rate = </p>
									<p style="margin-bottom: 5px;">conv1_dim = </p>
									<p style="margin-bottom: 5px;">conv2_dim = </p>	 -->
								
								<h3 id="pokemonaipage_3_3">3.3 Model Pretraining and Reinforcement Learning Training</h3>
								<p style="margin-bottom: 5px;">Prior to reinforcement learning, the mdoel was trained on foundational knowledge through gameplay states/action in order to optmize the learning process.</p>

								<h4>Reinforcement Learning Training Loop</h4>
								<span class="image main">
								    <img class="project-image" src="images/projects/pokemonplatinumai/RLHF-diagram.jpeg" alt="" style="display: block; margin: auto; width: 70%; max-width: 800px;" />
								</span>
								<p style= "margin-top:-10px;">*Note that this is for exploitation, not exploration.</p>
								
								<h3 id="pokemonaipage_3_4">3.4 EVALUATION</h3>
								<p>The evaluation phase focused on assessing the model's performance in object detection and gameplay decision-making accuracy.</p>
								<ul style="margin-left: 20px;">
								    <li><strong>Computer Vision Model Metrics</strong>:
									<ul style="margin-left: 20px; margin-bottom:5px;">
									    <li>Mean Average Precision (mAP): Used to measure detection accuracy for Pokémon, items, and NPCs.</li>
									    <li>Precision and Recall: Evaluated to ensure a balance between correctly identifying objects and avoiding false positives.</li>
									</ul>
								    </li>
								    <li><strong>Gameplay Model Metrics</strong>:
									<ul style="margin-left: 20px; margin-bottom:5px;">
									    <li>Accuracy of Actions: Percentage of correct actions taken by the model during gameplay.</li>
									    <li>Reward Score: Cumulative reward achieved per episode to assess decision-making quality in achieving game objectives.</li>
									    <li>Consistency: Frequency of successful task completions (e.g., navigating to specific locations).</li>
									</ul>
								    </li>
								    <li><strong>Human Feedback Integration</strong>: Analyzed the model’s improvement in decision-making accuracy based on human feedback adjustments.</li>
								    <li><strong>Real-Time Performance</strong>: Ensured that the model could perform efficiently within the game environment with minimal lag or delays.</li>
								</ul>

								<p>Model pretraining script <a href="https://github.com/scottpitcher/PokemonPlatinum.AI/blob/main/model_pretraining.ipynb">here!</a></p>
								<p>Reinforcement learning scripts <a href="https://github.com/scottpitcher/PokemonPlatinum.AI/tree/main/RLHF_Scripts">here!</a></p>

								</details>

								<details>
								  <summary>
								<h2 id="pokemonaipage_4">4. Challenges and Solutions</h2>
								  </summary>
								<div class="table-wrapper">
									<table class="alt">
										<thead>
											<tr>
												<th>Challenge</th>
												<th>Solution</th>
												<th>Result</th>
											</tr>
										</thead>
										<tbody>
											<tr>
											    <td><strong>Limited Dataset for Training Computer Vision Model</strong></td>
											    <td>Manually annotated a small set of images (150) and applied data augmentation techniques (rotation, color jitter, contrast adjustments).</td>
											    <td>Achieved 70%+ accuracy on key object detection (Pokémon, NPCs), verified on test data with diverse augmentations.</td>
											</tr>
											<tr>
											    <td><strong>Managing Memory for Contextual Gameplay</strong></td>
											    <td>Implemented an extended LSTM module to retain game context (map location, Pokémon health, etc.).</td>
											    <td>Improved task performance by 25% in complex scenarios requiring memory, such as revisiting NPCs or avoiding areas with low health.</td>
											</tr>
											<tr>
											    <td><strong>Difficulty in Model Tuning for Real-Time Gameplay</strong></td>
											    <td>Applied hyperparameter tuning and used human feedback to optimize the LSTM model's parameters.</td>
											    <td>Reached 90% success in task completion (e.g., navigating to locations) across test runs.</td>
											</tr>
											<tr>
											    <td><strong>Handling Diverse Game Scenarios</strong></td>
											    <td>Used reinforcement learning with human feedback to train the model across varied scenarios.</td>
											    <td>Enhanced model’s flexibility, achieving a 15% reduction in failed actions during unpredictable events or rare situations.</td>
											</tr>
											<tr>
											    <td><strong>Action Space Complexity in Reinforcement Learning</strong></td>
											    <td>Simplified the action space to directional and core commands (A, B, X, Y) for efficient learning.</td>
											    <td>Reduced training time by 30%, with a 20% improvement in episode convergence rates.</td>
											</tr>
										</tbody>
									</table>
								</div>
								</details>

								<details>
								  <summary>
								  <h2 id="pokemonaipage_5">5. Results</h2>
								  </summary>
								<p>The results showcase the model’s effectiveness across object detection and gameplay decision-making, with improvements observed through human feedback integration and real-time performance.</p>
								<ul style="margin-left: 20px;">
								    <li><strong>Computer Vision Model</strong>:
								        <ul style="margin-left: 20px; margin-bottom:5px;">
								            <li><strong>Mean Average Precision (mAP)</strong>: Achieved 70.5% for detecting Pokémon, items, and NPCs accurately.</li>
										<details>
										  <summary><p style="margin-bottom: 5px;">Show graph</p></summary>
										<span class="image main">
										    <img class="project-image" src="images/projects/pokemonplatinumai/perclass_mAP.png" alt="" style="display: block; margin: auto; width: 70%; max-width: 800px;" />
										  </span>
										</details>
								            <li><strong>Precision and Recall</strong>: The model achieved a balanced precision and recall of approximately 80%, effectively reducing false positives while accurately identifying in-game objects.</li>
								       		<details>
										  <summary><p style="margin-bottom : 0px;">Show graph</p></summary>
										<span class="image main">
										    <img class="project-image" src="images/projects/pokemonplatinumai/Pres-Rec-curve.png" alt="" style="display: block; margin: auto; width: 70%; max-width: 800px;" />
										  </span>
										</details>
									</ul>
								    </li>
								    <li><strong>Gameplay Model</strong>:
								        <ul style="margin-left: 20px; margin-bottom:5px;">
								            <li><strong>Action Accuracy</strong>: Attained 82% action accuracy, indicating consistent correct decisions during gameplay.</li>
								            <li><strong>Reward Score</strong>: Averaged a cumulative reward score of 160 per episode, demonstrating effective decision-making aligned with game objectives.</li>
								            <li><strong>Task Consistency</strong>: Successfully completed navigation tasks 75% of the time, reliably reaching designated locations in the game.</li>
								        </ul>
								    </li>
								    <li><strong>Human Feedback Integration</strong>: Increased action accuracy by 12% post-feedback, enhancing decision quality and responsiveness to in-game challenges.</li>
								    <li><strong>Real-Time Performance</strong>: Achieved smooth operation with <1-second response time, maintaining real-time gameplay without perceptible lag.</li>
								</ul>
								</details>

								<details>
								  <summary>
								  <h2 id="pokemonaipage_6">6. Conclusion & Future Improvements</h2>
								  </summary>
								<h3>Conclusion</h3>
								<p style="margin-left: 10px; margin-bottom: 5px;">As a personal project, this project laid the foundation for the feasibility of using a combination of computer vision and reinforcement learning to create an AI model that can autonomously navigate and interact within a complex open-world game</p>
								<p style="margin-left: 10px; margin-bottom: 5px;">With the incorporation of human feedback, the model's performance was refined, making it adaptable to real-time challenges.</p>
								<h3>Future Improvements</h3>
								<p style="margin-left: 10px; margin-bottom: 5px;"><strong>Fine-Tune Reward Structure: </strong>: Enhance the reward system in the reinforcement learning model to incentivize more complex in-game strategies and behaviors. </p>
								<p style="margin-left: 10px; margin-bottom: 5px;"><strong>Explore Multi-Agent Scenarios: </strong>: Develop the model to handle multi-agent environments or interactions with multiple NPCs for a richer gaming experience.</p>
								<p style="margin-left: 10px; margin-bottom: 5px;"><strong>Enhance Model Memory: </strong>: Implement a memory module (e.g., extended LSTM or transformer-based) to track map, location, Pokémon status, and recent actions, enabling strategy based on game history.</p>
								</details>
								

								
							</article>
						<!--Knowledge Graph Project -->
							<article id="knowledgemoviepage">
								<h1 class="major">Knowledge Graph Movie Recommender GNN </h1>
								<div style="text-align: center;">
								<span>
								  <img 
								    style="width: 100%; max-width: 500px; height: 420px; object-fit: contain;" 
								    class="project-image" 
								    src="images/projects/knowldgegraphmovierec/graph.png" 
								    alt="Knowledge Graph Movie Recommendation Visualization" 
								  />
								</span>
								</div>
								<!-- Movie Recommendation Dropdowns -->
								<div id="movie-recommendation" style="text-align: center; margin-bottom: 30px;">
								    <form id="movieForm">
								        <label for="movie1">Movie 1: </label>
								        <select id="movie1">
								            <option value="">Select a movie</option>
								        </select>
								
								        <label for="movie2">Movie 2:</label>
								        <select id="movie2">
								            <option value="">Select a movie</option>
								        </select>
								
								        <label for="movie3">Movie 3:</label>
								        <select id="movie3">
								            <option value="">Select a movie</option>
								        </select>
								
								        <br><br>
								        <button type="submit">Get Recommendation</button>
								    </form>
								
								    <div id="result" style="margin-top: 10px;"></div>
								</div>
								
								<script>
								    // Fetch movie data for dropdowns
								  async function populateDropdowns() {
								    try {
								        const response = await fetch("https://movie-recommendation-api-385067038431.us-central1.run.app/dropdown");
								        const data = await response.json();
								        console.log("Fetched movie data:", data);  // Add this line to log the fetched data
								
								        const movieTitles = data.movies;
								
								        // Populate dropdowns with movie titles
								        const movieSelectElements = [document.getElementById('movie1'), document.getElementById('movie2'), document.getElementById('movie3')];
								
								        movieTitles.forEach(movie => {
								            const option = document.createElement("option");
								            option.value = movie.InputMovie_id;
								            option.textContent = movie.InputMovie_title;
								
								            movieSelectElements.forEach(select => {
								                select.appendChild(option.cloneNode(true));  // Add the same options to each dropdown
								            });
								        });
								    } catch (error) {
								        console.error("Error fetching movie data:", error);
								    }
								}
								
								    // Handle form submission and fetch recommendation
								    document.getElementById("movieForm").addEventListener("submit", async function (event) {
								        event.preventDefault();
								
								        // Get selected movie IDs
								        const selectedMovies = [
								            document.getElementById('movie1').value,
								            document.getElementById('movie2').value,
								            document.getElementById('movie3').value
								        ];
								
								        if (selectedMovies.some(id => id === "")) {
								            document.getElementById('result').innerText = "Please select 1 to 3 movies.";
								            return;
								        }
								
								        try {
								            // Send the selected movies to the /recommend endpoint
								            const response = await fetch("https://movie-recommendation-api-385067038431.us-central1.run.app/recommend", {
										    method: "POST",
										    headers: {
										        "Content-Type": "application/json"
										    },
										    body: JSON.stringify({ input_movie_ids: selectedMovies })
										});

								
								            const recommendation = await response.json();
								
								            // Display the result
								            if (response.ok) {
								                document.getElementById('result').innerHTML = `
								                    <h3>Recommended Movie:</h3>
								                    <p><strong>${recommendation.recommended_movie}</strong></p>
								                    <p>Match Score: ${recommendation.match_score}</p>
								                `;
								            } else {
								                document.getElementById('result').innerText = recommendation.detail || "An error occurred.";
								            }
								        } catch (error) {
								            document.getElementById('result').innerText = "Error fetching recommendation.";
								            console.error("Error submitting form:", error);
								        }
								    });
								
								    // Populate dropdowns when the page loads
								    window.onload = populateDropdowns;
								</script>
								<div style="text-align: center;"><p>Movie data knowledge graph in Neo4j! <br>(Blue:Year, Orange:Genre, Purple:Title, Red: Popularity)</p></div>
								<h2>Project Summary</h2>
								<p><p>
								<p>Check out the GitHub repository <a href="https://github.com/scottpitcher/movie-recommendation-network">here!</a></p>
								<h2>Project Overview</h2>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_1"> 1. Introduction & Technical Stack</a></p>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_2"> 2. Dataset and Preprocessing </a></p>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_3"> 3. Project Structure </a></p> <details><summary style="font-size: 0.9em;"><p style="margin-bottom : 0px;">Subsections</p></summary>
								    <p style="margin-left: 20px; font-size: 0.9em; margin-bottom: 3px;"><a href="#knowledgemoviepage_3_1">3.1 Computer Vision Model</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#knowledgemoviepage_3_2">3.2 Model Building and Hyperparameter Tuning</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#knowledgemoviepage_3_3">3.3 Model Pretraining and Reinforcement Learning Training</a></p>
								    <p style="margin-left: 20px; font-size: 0.9em;margin-bottom: 3px;"><a href="#knowledgemoviepage_3_4">3.4 Evaluation</a></p>
								</details>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_4"> 4. Challenges and Solutions </a></p>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_5"> 5. Results </a></p>
								<p style="margin-bottom: 5px;"><a href="#knowledgemoviepage_6"> 6. Conclusion & Future Improvements </a></p>
								<hr width="100%" size="2">
			</article>
						<!--Personalized Daily News Summarizer -->
							<article id="newsretrievalpage">
								<h1 class="major">Personalized Daily News Summarizer </h1>
								<div style="text-align: center;">
								<span>
								  <img 
								    style="width: 100%; max-width: 500px; height: 420px; object-fit: contain;" 
								    class="project-image" 
								    src="images/news_summarizer_image.png" 
								    alt="News Summariser Image" 
								  />
								</span>
								</div>
								<!--Deployed model -->
									 <h1>Ask About the News</h1>
									
									  <input type="text" id="query" placeholder="Ask a question..." size="40" /> <br>
									  <i>*The app is hosted on Render, a free deployment service, so please allow up to 60 seconds for a response to be generated!</i><br>
									  <button onclick="submitQuery()">Search</button>
								          <div id="status" style="margin-top: 10px; font-weight: bold;"></div>
									  <div id="matches"></div>
									  <div id="summary"></div>
									
									 <script>
  async function submitQuery() {
    const query = document.getElementById("query").value;
    const statusDiv = document.getElementById("status");
    const summaryDiv = document.getElementById("summary");
    const matchesDiv = document.getElementById("matches");

    // Clear previous results
    statusDiv.innerText = "⏳ Sending your query...";
    summaryDiv.innerHTML = "";
    matchesDiv.innerHTML = "";

    try {
      const response = await fetch("https://personalised-news-summariser-rag-llm.onrender.com/query", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ query })
      });

      if (!response.ok) {
        statusDiv.innerText = `❌ Error: ${response.status} ${response.statusText}`;
        return;
      }

      const data = await response.json();

      if (!data.summary) {
        statusDiv.innerText = "⚠️ No summary returned. Try a different query?";
        return;
      }

      statusDiv.innerText = "✅ Results loaded!";
      summaryDiv.innerHTML = `<h3>Summary:</h3><p>${data.summary}</p>`;

      if (data.matches && data.matches.length > 0) {
        matchesDiv.innerHTML = "<h4>Top Matches:</h4>" + data.matches.map(m => `<p>${m}</p>`).join("");
      } else {
        matchesDiv.innerText = "⚠️ No article matches found.";
      }

    } catch (error) {
      statusDiv.innerText = "🚨 Network error. Check the API or internet connection.";
      console.error("Fetch failed:", error);
    }
  }
</script>
								<p>Check out the GitHub repository <a href="https://github.com/scottpitcher/personalised_news_summariser_rag_llm">here!</a></p>
								<h2>Project Overview</h2>
								<p style="margin-bottom: 5px;"><a href="#newsretrievalpage_1"> 1. Introduction & Technical Stack</a></p>
								<p style="margin-bottom: 5px;"><a href="#newsretrievalpage_2"> 2. Samples of Code </a></p>
								<p style="margin-bottom: 5px;"><a href="#newsretrievalpage_3"> 3. Roadblocks, Solutions, Improvements </a></p>
								<p style="margin-bottom: 5px;"><a href="#newsretrievalpage_4"> 4. Example Outputs </a></p>
								<hr width="100%" size="2">
								
								<details>
								  <summary>
								    <h2 id="newsretrievalpage_1">1. Introduction & Technical Stack</h2>
								  </summary>
								  <p style="margin-bottom: 15px;">
									I set out to create a system that helps users reduce the time needed to find answers about current events.
									With information overload being a common challenge, I developed this app to allow users to ask direct questions and receive transparent, concise answers.
									The system leverages the NewsAPI to regularly scrape current news, maintaining an up-to-date vector store of information. I implemented Retrieval-Augmented Generation (RAG) to efficiently access relevant content, and incorporated Reinforcement Learning to collect user feedback on tone and style — allowing the QA bot to adapt to individual conversation habits and feel more natural.								  </p>
							<table>
							  <thead>
							    <tr>
							      <th>Component</th>
							      <th>Tool</th>
							    </tr>
							  </thead>
							  <tbody>
							    <tr><td>Language</td><td>Python</td></tr>
							    <tr><td>Retrieval</td><td>FAISS </td></tr>
							    <tr><td>Embeddings</td><td>sentence-transformers / OpenAI Embeddings</td></tr>
							    <tr><td>LLMs</td><td>OpenAI GPT-4 models</td></tr>
							    <tr><td>Summarization</td><td>LangChain / Custom Prompt Templates</td></tr>
							    <tr><td>UI (Optional)</td><td>lask</td></tr>
							    <tr><td>Data Storage</td><td>JSON / CSV</td></tr>
							  </tbody>
							</table>
								</details>
								
								<details>
								  <summary>
									<h2 id="newsretrievalpage_2">2. Samples of Code</h2>
								</summary>
									
									<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>URL Fetching Script</span>
										</summary>
									 <pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python"># query_and_summarize.py

# The focus of this script is to  
## Embed a user query,
## Search the FAISS vector store,
## Retrieve the top article contents,
## Send them to an LLM for summarization
import os
import faiss
import pickle
import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv
load_dotenv(override=False)

# Config
os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
VECTOR_STORE_DIR = Path("data/vector_store")
FULL_TEXT_DIR = Path("data/full_text")
MODEL_NAME = "all-MiniLM-L6-v2" # Model for embedding
RELEVANCE_THRESHOLD = 1.2       # controls relevance of chosen articles
TOP_K = 3                       # Number of top articles to retrieve

# Set up openai
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# Load vector index and metadata
index = faiss.read_index(str(VECTOR_STORE_DIR / "global_index.faiss"))
with open(VECTOR_STORE_DIR / "global_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

# Load embedding model
model = SentenceTransformer(MODEL_NAME)

# Lookup article content by URL + date
def get_article_content(url, date):
    file_path = FULL_TEXT_DIR / f"{date}.json"
    if not file_path.exists():
        return None

    with open(file_path, "r") as f:
        articles = json.load(f)
        for article in articles:
            if article.get("url") == url:
                return article.get("content")
    return None

# Generate summary using OpenAI
def summarize_articles(query, articles_text):
    prompt = f"""
You are a helpful assistant summarizing current news for a user.
It is important the response only pertains to the user's query.
If there is not enough information to answer accurately, indicate a lack of knowledge. 

User asked: "{query}"

Based on the following articles, provide a clear, casual answer to the query.:

{articles_text}
    """.strip()

    client = OpenAI()  # uses OPENAI_API_KEY env var
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{ "role": "user", "content": prompt }],
        temperature=0.7,
        max_tokens=500,
    )
    return response.choices[0].message.content.strip()

# Main query pipeline
def query_news(query):
    query_embedding = model.encode([query])

    # D: Query-Embedding distance; I: Indices of matched vectors
    D, I = index.search(query_embedding, TOP_K)

    selected_texts = []
    match_summaries = []  # store printable match strings
    print("\nTop Matches:\n" + "-"*40)

    for i, score in zip(I[0], D[0]):
        article = metadata[i]
        title = article['title']
        source = article['source']
        score_str = f"{score:.4f}"

        content = get_article_content(article["url"], article["date"])
        status = "[KEPT]" if score <= RELEVANCE_THRESHOLD and content else "[OMITTED]"

        match_str = f"""📌 {title} {status}
        • Source: {source}, {article['date']}
        • Relevance Score: {score:.4f}"""

        print(match_str)
        match_summaries.append(match_str)
        
        if score <= RELEVANCE_THRESHOLD and content:
            selected_texts.append(content)

    if not selected_texts:
        print("No matching content found.")
        return {
            "summary": "I'm sorry, I couldn't find any relevant articles.",
            "matches": match_summaries
        }

    all_text = "\n\n---\n\n".join(selected_texts)
    summary = summarize_articles(query, all_text)

    print("\nSummary:\n" + "-"*40)
    print(summary)

    return {
        "summary": summary or "Sorry, no summary could be generated.",
        "matches": match_summaries
    }


# Run
if __name__ == "__main__":
    user_query = input("What would you like to know about? ")
    query_news(user_query)

									</code></pre>
								</details>

								<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>Article Embedding Script</span>
										</summary>
									<pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python">import os
import json
import pickle
from pathlib import Path
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
import faiss

# Setup
os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
FULL_TEXT_DIR = Path("data/full_text")
VECTOR_STORE_DIR = Path("data/vector_store")
MODEL_NAME = "all-MiniLM-L6-v2"

INDEX_PATH = VECTOR_STORE_DIR / "global_index.faiss"
META_PATH = VECTOR_STORE_DIR / "global_metadata.pkl"
SEEN_PATH = VECTOR_STORE_DIR / "seen_articles.json"

print("Importing model...")
model = SentenceTransformer(MODEL_NAME)

def load_seen_urls():
    print("Loading seen files...")
    if SEEN_PATH.exists() and SEEN_PATH.stat().st_size > 0:
        try:
            with open(SEEN_PATH, "r") as f:
                return set(json.load(f).get("embedded_urls", []))
        except json.JSONDecodeError:
            print("[!] JSON file was empty or malformed. Starting fresh.")
    return set()

def save_seen_urls(urls):
    print("Saving seen files...")
    with open(SEEN_PATH, "w") as f:
        json.dump({"embedded_urls": list(urls)}, f, indent=2)

def load_existing_index_and_metadata():
    print("Importing FAISS file...")
    if INDEX_PATH.exists() and META_PATH.exists():
        index = faiss.read_index(str(INDEX_PATH))
        with open(META_PATH, "rb") as f:
            metadata = pickle.load(f)
        return index, metadata
    return None, []

def embed_new_articles():
    print("Searching files...")
    all_files = sorted(FULL_TEXT_DIR.glob("*.json"))
    seen_urls = load_seen_urls()
    index, metadata = load_existing_index_and_metadata()

    new_texts = []
    new_metadata = []

    print("Filtering out seen files...")
    for file in all_files:
        with open(file, "r") as f:
            articles = json.load(f)

        for article in articles:
            url = article.get("url")
            content = article.get("content", "").strip()
            if not url or not content or url in seen_urls:
                continue

            new_texts.append(content)
            new_metadata.append({
                "title": article.get("title", ""),
                "url": url,
                "source": article.get("source", ""),
                "category": article.get("category", ""),
                "date": file.stem  # e.g. "2025-03-25"
            })
            seen_urls.add(url)

    if not new_texts:
        print("No new articles to embed.")
        return

    print(f"Embedding {len(new_texts)} new articles...")
    embeddings = model.encode(new_texts, show_progress_bar=True)

    # Build or update index
    dim = embeddings.shape[1]
    if index is None:
        index = faiss.IndexFlatL2(dim)
    index.add(embeddings)

    # Extend and save metadata
    metadata.extend(new_metadata)
    VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)
    faiss.write_index(index, str(INDEX_PATH))
    with open(META_PATH, "wb") as f:
        pickle.dump(metadata, f)
    save_seen_urls(seen_urls)

    print(f"Updated global index with {len(new_texts)} articles.")

if __name__ == "__main__":
    embed_new_articles()

										</code></pre>
								</details>
								<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>Query and Summarise Script</span>
										</summary>
									<pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python"># query_and_summarize.py

# The focus of this script is to  
## Embed a user query,
## Search the FAISS vector store,
## Retrieve the top article contents,
## Send them to an LLM for summarization
import os
import faiss
import pickle
import json
from pathlib import Path
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from tqdm import tqdm
from dotenv import load_dotenv
load_dotenv(override=False)

# Config
os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
VECTOR_STORE_DIR = Path("data/vector_store")
FULL_TEXT_DIR = Path("data/full_text")
MODEL_NAME = "all-MiniLM-L6-v2" # Model for embedding
RELEVANCE_THRESHOLD = 1.2       # controls relevance of chosen articles
TOP_K = 3                       # Number of top articles to retrieve

# Set up openai
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# Load vector index and metadata
index = faiss.read_index(str(VECTOR_STORE_DIR / "global_index.faiss"))
with open(VECTOR_STORE_DIR / "global_metadata.pkl", "rb") as f:
    metadata = pickle.load(f)

# Load embedding model
model = SentenceTransformer(MODEL_NAME)

# Lookup article content by URL + date
def get_article_content(url, date):
    file_path = FULL_TEXT_DIR / f"{date}.json"
    if not file_path.exists():
        return None

    with open(file_path, "r") as f:
        articles = json.load(f)
        for article in articles:
            if article.get("url") == url:
                return article.get("content")
    return None

# Generate summary using OpenAI
def summarize_articles(query, articles_text):
    prompt = f"""
You are a helpful assistant summarizing current news for a user.
It is important the response only pertains to the user's query.
If there is not enough information to answer accurately, indicate a lack of knowledge. 

User asked: "{query}"

Based on the following articles, provide a clear, casual answer to the query.:

{articles_text}
    """.strip()

    client = OpenAI()  # uses OPENAI_API_KEY env var
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{ "role": "user", "content": prompt }],
        temperature=0.7,
        max_tokens=500,
    )
    return response.choices[0].message.content.strip()

# Main query pipeline
def query_news(query):
    query_embedding = model.encode([query])

    # D: Query-Embedding distance; I: Indices of matched vectors
    D, I = index.search(query_embedding, TOP_K)

    selected_texts = []
    match_summaries = []  # store printable match strings
    print("\nTop Matches:\n" + "-"*40)

    for i, score in zip(I[0], D[0]):
        article = metadata[i]
        title = article['title']
        source = article['source']
        score_str = f"{score:.4f}"

        content = get_article_content(article["url"], article["date"])
        status = "[KEPT]" if score <= RELEVANCE_THRESHOLD and content else "[OMITTED]"

        match_str = f"""📌 {title} {status}
        • Source: {source}, {article['date']}
        • Relevance Score: {score:.4f}"""

        print(match_str)
        match_summaries.append(match_str)
        
        if score <= RELEVANCE_THRESHOLD and content:
            selected_texts.append(content)

    if not selected_texts:
        print("No matching content found.")
        return {
            "summary": "I'm sorry, I couldn't find any relevant articles.",
            "matches": match_summaries
        }

    all_text = "\n\n---\n\n".join(selected_texts)
    summary = summarize_articles(query, all_text)

    print("\nSummary:\n" + "-"*40)
    print(summary)

    return {
        "summary": summary or "Sorry, no summary could be generated.",
        "matches": match_summaries
    }


# Run
if __name__ == "__main__":
    user_query = input("What would you like to know about? ")
    query_news(user_query)
										
									</code></pre>
								</details>
								
								</details>
								
								<details>
								  <summary>
								    <h2 id="newsretrievalpage_3">3. Roadblocks, Solutions, Improvements</h2>
								  </summary>
								  <table>
									  <thead>
									    <tr>
									      <th>Roadblock</th>
									      <th>Solution</th>
									    </tr>
									  </thead>
									  <tbody>
									    <tr>
									      <td>No inherent 'politics' category in NewsAPI</td>
									      <td>Created custom category using keyword search via the everything endpoint</td>
									    </tr>
									    <tr>
									      <td>LLM Output irrelevant to user query</td>
									      <td>Retrieved articles via semantic similarity (FAISS), applied a similarity threshold, and returned a fallback "unsure" answer if no context was strong enough</td>
									    </tr>
									    <tr>
									      <td>Bias transparency</td>
									      <td><strong>Potential addition(s)</strong>: Keep database of sources with bias scores, train new agent to scan for bias and generate score.</td>
									    </tr>
									    <tr>
									      <td>Dated articles</td>
									      <td><strong>Potential addition(s)</strong>: Implement system to weight articles via date, or omit after certain timeframe.</td>
									    </tr>
									  </tbody>
									</table>
									
								<p style="font-size: 0.8em;"><i>*Note: all <strong>potential additions</strong> have not been added yet, and are stated to address gaps in project application.</i></p>

								</details>

								
								<details>
								  <summary>
								    <h2 id="newsretrievalpage_4">4. Example Outputs</h2>
								  </summary>
									<h3>Example 1: Politics</h3>
									<img src="https://raw.githubusercontent.com/scottpitcher/personalised_news_summariser_rag_llm/main/images/Example%20Query%201.png" alt="Example Query 1" style="max-width: 100%; height: auto;" />
									
									<h3>Example 2: Economy</h3>
									<img src="https://raw.githubusercontent.com/scottpitcher/personalised_news_summariser_rag_llm/main/images/Example%20Query%202.png" alt="Example Query 2" style="max-width: 100%; height: auto;" />
									
									<h3>Example 3: Science</h3>
									<img src="https://raw.githubusercontent.com/scottpitcher/personalised_news_summariser_rag_llm/main/images/Example%20Query%203.png" alt="Example Query 3" style="max-width: 100%; height: auto;" />

								</details>

								
			</article>
						<!-- Siamese Facial Recognition Network -->
							<article id="siamesenetworkpage">
								<h1 class="major">Siamese Facial Recognition Network </h1>
								<div style="text-align: center;">
								<span>
								 <video
								  style="width: 100%; max-width: 500px; height: 420px; object-fit: contain;"
								  class="project-video"
								  controls
								>
								  <source src="images/siamese_demo.mov" type="video/quicktime">
								  Your browser doesn’t support embedded videos.
								</video>
								</span>
								</div>
								
								<p>Check out the GitHub repository <a href="https://github.com/scottpitcher/siamese_facial_recog_app">here!</a></p>
								<h2>Project Overview</h2>
								<p style="margin-bottom: 5px;"><a href="#siamesenetworkpage_1"> 1. Introduction & Technical Stack</a></p>
								<p style="margin-bottom: 5px;"><a href="#siamesenetworkpage_2"> 2. Samples of Code </a></p>
								<p style="margin-bottom: 5px;"><a href="#siamesenetworkpage_3"> 3. Roadblocks, Solutions, Improvements </a></p>
								<p style="margin-bottom: 5px;"><a href="#siamesenetworkpage_4"> 4. Example Outputs </a></p>
								<hr width="100%" size="2">
								
								<details>
								  <summary>
								    <h2 id="siamesenetworkpage_1">1. Introduction & Technical Stack</h2>
									  
								  </summary>
								  <p style="margin-bottom: 15px;">
									  This project is a robust face‐matching system that leverages a Siamese CNN and OpenCV/MediaPipe preprocessing to verify identities by comparing face embeddings. It isolates the face region to eliminate background bias and achieves high accuracy even in previously unseen environments.
								  </p>
									  
							<table>
							  <thead>
							    <tr>
							      <th>Component</th>
							      <th>Tool</th>
							    </tr>
							  </thead>
							  <tbody>
								<tr><td>Language</td><td>Python</td></tr>
								<tr><td>Framework</td><td>TensorFlow / Keras</td></tr>
								<tr><td>Data Pipeline</td><td>tf.data API</td></tr>
								<tr><td>Computer Vision</td><td>OpenCV (webcam capture)</td></tr>
								<tr><td>Model</td><td>Custom Siamese CNN with L1-distance layer</td></tr>
								<tr><td>Visualization</td><td>Matplotlib (saliency maps)</td></tr>
								<tr><td>Data Storage</td><td>Local image files &amp; LFW dataset</td></tr>

							  </tbody>
							</table>
								</details>
	
								<details>
								  <summary>
								    <h2 id="#siamesenetworkpage_2"> 2. Samples of Code </h2>
								  </summary>
									
								<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>Custom L1 Distance Function</span>
										</summary>
									 <pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python"># Siamese L1 distance class
class L1Dist(Layer):
    def __init__(self, **kwargs):
        super().__init__()
    
    # Distance calc
    def call(self, input_embedding, validation_embedding):
        return tf.math.abs(input_embedding - validation_embedding)

										 
									</code></pre>
								</details>
									
								<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>TensorFlow Model Architecture</span>
										</summary>
									 <pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python">def make_embedding():
    inp = Input(shape=(100,100,3), name='embed_input')
    
    # ── BLOCK 1 ── capture large-ish patterns with a 7×7 kernel
    c1 = Conv2D(32, (7,7), activation='relu', padding='same')(inp)   # 32 filters × 7×7
    m1 = MaxPooling2D((2,2), padding='same')(c1)                    # downsample by 2
    
    # ── BLOCK 2 ── mid-range patterns with a 5×5 kernel
    c2 = Conv2D(64, (5,5), activation='relu', padding='same')(m1)    # 64 filters × 5×5
    m2 = MaxPooling2D((2,2), padding='same')(c2)                    # downsample by 2
    
    # ── BLOCK 3 ── finer details with a 3×3 kernel
    c3 = Conv2D(128, (3,3), activation='relu', padding='same')(m2)   # 128 filters × 3×3
    m3 = MaxPooling2D((2,2), padding='same')(c3)                    # downsample by 2
    
    # ── BLOCK 4 ── high-level cues with a 3×3 kernel
    c4 = Conv2D(256, (3,3), activation='relu', padding='same')(m3)   # 256 filters × 3×3
    
    # ── EMBEDDING ── flatten to vector + dense
    f1 = Flatten()(c4)                                              # shape ~ (13×13×256)=43264
    d1 = Dense(4096, activation='sigmoid')(f1)                     # final 4096-D embedding
    
    return Model(inputs=inp, outputs=d1, name='embedding')
										 
									</code></pre>
								</details>

								<details class="subsection-wrapper">
										<summary class="subsection-label">
											<span>Siamese Model</span>
										</summary>
									 <pre class="code-block" style="max-height: 400px; overflow-y: scroll;"><code class="language-python"># implementation of the keras CNN embeddings

def make_siamese_model():
    # Anchor input
    input_image = Input(name = 'anchor_img', shape = (100,100,3))
    
    # Validation input
    validation_image = Input(name = 'validation_img', shape = (100,100,3))
    
    # Embed images
    ## Embed anchor
    input_embd = embedding(input_image)

    ## Embed val
    val_embd = embedding(validation_image)

    # Run siamese distance
    siamese_layer = L1Dist()
    siamese_layer._name = "distance"
    distances = siamese_layer(input_embd, val_embd)

    # Classification Layer
    classifier = Dense(1, activation = 'sigmoid')(distances)

    return Model(inputs= [input_image, validation_image], outputs = classifier, name = 'SiameseNetwork')

siamese_model = make_siamese_model()
siamese_model.summary()
										 
									</code></pre>
								</details>
									
								</details>

								<details>
								  <summary>
								    <h2 id="#siamesenetworkpage_3"> 3. Roadblocks, Solutions, Improvements </h2>
								  </summary>
								</details>

								<details>
								  <summary>
								    <h2 id="#siamesenetworkpage_4"> 4. Example Outputs </h2>
								  </summary>
								</details>

								
							</article>
						
								


						<!--E-Commerce Project -->
							<article id="ecommercepage">
								<h2 class="major"> E-Commerce</h2>
								<h3>Project Summary</h3>
								<p><p>
								<p>Check out the full GitHub repository <a href="https://github.com/scottpitcher/ecommerce-marketing-analytics-optimization">here!</a></p>
								
							</article>
						<!--Spotify Project -->
							<article id="spotifypage">
								<h2 class="major">Spotify Recommendation Model and Customer Churn Optimization</h2>
								<h3>Project Summary</h3>
								<p><p>
								<p>Check out the full GitHub repository <a href="https://github.com/scottpitcher/spotify-user-engagement">here!</a></p>
								
							</article>
						
						<!-- Elements -->
							<article id="elements">
								<h2 class="major">Elements</h2>

								<section>
									<h3 class="major">Text</h3>
									<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
									This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
									This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
									<hr />
									<h2>Heading Level 2</h2>
									<h3>Heading Level 3</h3>
									<h4>Heading Level 4</h4>
									<h5>Heading Level 5</h5>
									<h6>Heading Level 6</h6>
									<hr />
									<h4>Blockquote</h4>
									<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
									<h4>Preformatted</h4>
									<pre><code>i = 0;
while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
								</section>

								<section>
									<h3 class="major">Lists</h3>

									<h4>Unordered</h4>
									<ul>
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Alternate</h4>
									<ul class="alt">
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Ordered</h4>
									<ol>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis viverra.</li>
										<li>Felis enim feugiat.</li>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis lorem.</li>
										<li>Felis enim et feugiat.</li>
									</ol>
									<h4>Icons</h4>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/scottpitcher1" class="icon brands fa-linkedin"><span class="label">Instagram</span></a></li>
										<li><a href="https://www.github.com/scottpitcher" class="icon brands fa-github"><span class="label">Github</span></a></li>
									</ul>

									<h4>Actions</h4>
									<ul class="actions">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Table</h3>
									<h4>Default</h4>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>

									<h4>Alternate</h4>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>
								</section>

								<section>
									<h3 class="major">Buttons</h3>
									<ul class="actions">
										<li><a href="#" class="button primary">Primary</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button">Default</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
										<li><a href="#" class="button icon solid fa-download">Icon</a></li>
									</ul>
									<ul class="actions">
										<li><span class="button primary disabled">Disabled</span></li>
										<li><span class="button disabled">Disabled</span></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Form</h3>
									<form method="post" action="#">
										<div class="fields">
											<div class="field half">
												<label for="demo-name">Name</label>
												<input type="text" name="demo-name" id="demo-name" value="" placeholder="Jane Doe" />
											</div>
											<div class="field half">
												<label for="demo-email">Email</label>
												<input type="email" name="demo-email" id="demo-email" value="" placeholder="jane@untitled.tld" />
											</div>
											<div class="field">
												<label for="demo-category">Category</label>
												<select name="demo-category" id="demo-category">
													<option value="">-</option>
													<option value="1">Manufacturing</option>
													<option value="1">Shipping</option>
													<option value="1">Administration</option>
													<option value="1">Human Resources</option>
												</select>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-low" name="demo-priority" checked>
												<label for="demo-priority-low">Low</label>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-high" name="demo-priority">
												<label for="demo-priority-high">High</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-copy" name="demo-copy">
												<label for="demo-copy">Email me a copy</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-human" name="demo-human" checked>
												<label for="demo-human">Not a robot</label>
											</div>
											<div class="field">
												<label for="demo-message">Message</label>
												<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
											</div>
										</div>
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</form>
								</section>

							</article>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
